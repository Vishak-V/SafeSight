#!/usr/bin/env python

import cv2
import base64
import time
import requests
import json
import io
from gtts import gTTS
import pygame
import sys
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# --- 1. Configuration ---

# Get API key from environment variables
API_KEY = os.getenv("GEMINI_API_KEY")

# This endpoint is for Gemini 1.5 Flash, which supports JSON output mode.
# Using 'generateContent' is the standard method.
API_ENDPOINT = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent?key={API_KEY}"

# The system prompt that defines the AI's role and output format.
# We explicitly request JSON output.
SYSTEM_PROMPT = (
    "You are a time-critical AI Safety Assistant for a person with low vision. "
    "Your sole purpose is to analyze the image for immediate, physical hazards "
    "(e.g., steps, spills, obstacles) and provide a concise scene description. "
    "PRIORITIZE SAFETY. Your entire response MUST be a single, valid JSON object "
    "adhering to this exact schema: "
    '{"hazard_detected": "YES/NO", "hazard_warning": "...", "description": "..."}. '
    "Do not include markdown backticks (```json) or any text outside the JSON structure."
)

# --- 2. Helper Functions ---

def initialize_systems():
    """Initializes OpenCV webcam and Pygame mixer."""
    print("Initializing systems...")
    
    # Initialize OpenCV Video Capture
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Could not open webcam.")
        return None, False
    
    # Initialize Pygame Mixer
    try:
        pygame.mixer.init()
    except pygame.error as e:
        print(f"Error initializing pygame.mixer: {e}")
        print("Audio feedback will be disabled. Check your audio drivers.")
        return cap, False # Return cap, but audio_ready is False
    
    print("Systems initialized. Starting real-time loop...")
    print("Press 'q' in the OpenCV window to quit.")
    return cap, True

def process_frame(frame):
    """Encodes a single frame to Base64 JPEG."""
    # STAGE 2: Optimized Encoding
    # Compress frame to JPEG byte buffer
    success, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
    if not success:
        print("Error: Failed to encode frame.")
        return None
    
    # Convert byte buffer to Base64 string
    base64_image = base64.b64encode(buffer).decode('utf-8')
    return base64_image

def get_analysis_from_api(base64_image):
    """Sends image to API and gets a JSON response."""
    # STAGE 3: LLM API Interaction
    headers = {
        "Content-Type": "application/json"
    }
    
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": SYSTEM_PROMPT},
                    {
                        "inlineData": {
                            "mimeType": "image/jpeg",
                            "data": base64_image
                        }
                    }
                ]
            }
        ],
        "generationConfig": {
            # This forces Gemini to output only JSON
            "responseMimeType": "application/json",
        }
    }
    
    # API Call
    response = requests.post(API_ENDPOINT, headers=headers, json=payload, timeout=10)
    response.raise_for_status() # Raise HTTPError for bad responses

    # STAGE 4: Structured Parsing
    # The API response is JSON, and its 'text' field contains the JSON string we want
    response_data = response.json()
    
    # Extract the JSON object generated by the model
    # Note: The structure is response -> candidates -> content -> parts -> text/json
    
    # Check if 'text' exists, which contains the JSON string
    if 'text' in response_data['candidates'][0]['content']['parts'][0]:
        model_output_json_string = response_data['candidates'][0]['content']['parts'][0]['text']
        return json.loads(model_output_json_string)
    else:
        # If 'text' is not present, the model might have returned a direct JSON
        # object, which `requests` might not parse as the 'parts' field.
        # This is a less common path with `responseMimeType`, but good to check.
        # For Gemini, the 'text' field is the standard way it returns the JSON string.
        print("Warning: API response format might be unexpected. Trying to parse.")
        # This will likely fail if the structure isn't as expected,
        # which is why the `try...except` block in main() is important.
        return response_data['candidates'][0]['content']['parts'][0]


def play_audio_feedback(text, audio_ready):
    """Generates TTS and plays it synchronously."""
    if not audio_ready:
        print(f"Audio (disabled): {text}")
        return # Skip if pygame.mixer failed to init

    # STAGE 5: Auditory Feedback (Memory-Based TTS)
    try:
        # --- MODIFICATION: ---
        # Stop any currently playing sound immediately.
        # This ensures high-priority warnings cut off old/lingering descriptions.
        pygame.mixer.stop()
        
        # Generate TTS audio and write to in-memory buffer
        tts = gTTS(text=text, lang='en')
        mp3_fp = io.BytesIO()
        tts.write_to_fp(mp3_fp)
        mp3_fp.seek(0) # Rewind the buffer

        # Synchronized Audio
        # Load the audio from the buffer into a Sound object
        sound = pygame.mixer.Sound(mp3_fp)
        sound.play()

        # CRITICAL: Wait for audio to finish
        print(f"Playing audio: \"{text}\"")
        while pygame.mixer.get_busy():
            pygame.time.wait(10) # Yield CPU, check every 10ms
            
            # Allow 'q' to interrupt audio playback
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("Interrupted audio with 'q'.")
                pygame.mixer.stop()
                return False # Return False to signal exit

    except Exception as e:
        print(f"TTS/Audio Error: {e}")
        # Don't crash, just log and continue
    
    return True # Return True to signal continue

# --- 3. Main Execution ---

def main():
    cap, audio_ready = initialize_systems()
    if cap is None:
        sys.exit(1)

    try:
        while True:
            # STAGE 1: Capture Frame
            ret, frame = cap.read()
            if not ret:
                print("Error: Failed to capture frame.")
                break

            # Display the frame (non-blocking)
            cv2.imshow('Real-time Visual Assistance', frame)

            # STAGE 2: Encode Frame
            base64_image = process_frame(frame)
            if base64_image is None:
                continue

            try:
                # STAGES 3 & 4: API Call and Parsing
                analysis = get_analysis_from_api(base64_image)
                
                # Extract data based on the required schema
                hazard_detected = analysis.get("hazard_detected", "NO")
                hazard_warning = analysis.get("hazard_warning", "No details provided.")
                description = analysis.get("description", "No description provided.")

                # STAGE 5: Auditory Feedback Logic
                if hazard_detected.upper() == "YES":
                    feedback_text = f"Warning: {hazard_warning}. {description}"
                else:
                    feedback_text = description
                
                # Play audio and check for 'q' interrupt
                if not play_audio_feedback(feedback_text, audio_ready):
                    break # User pressed 'q' during audio

            except requests.exceptions.RequestException as e:
                print(f"API Error: {e}")
                # Wait a bit before retrying
                time.sleep(1)
            except (json.JSONDecodeError, KeyError, IndexError, TypeError) as e:
                print(f"API Parsing Error: {e}")
                print(f"Received problematic data from API. Skipping frame.")
            except Exception as e:
                print(f"An unexpected error occurred: {e}")
                break

            # Frame Throttling (as requested)
            # This delay happens *after* audio finishes,
            # creating the synchronous ~2 FPS pipeline.
            #
            # --- MODIFICATION: ---
            # If a hazard was detected, we skip the sleep delay
            # to start processing the next frame immediately.
            if hazard_detected.upper() == "YES":
                print("Hazard detected, skipping delay to process next frame.")
            else:
                time.sleep(0.5)

            # Graceful Exit Check (primary check)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("'q' pressed, shutting down.")
                break

    finally:
        # Cleanup
        print("Releasing resources...")
        cap.release()
        cv2.destroyAllWindows()
        if audio_ready:
            pygame.mixer.quit()
        print("Shutdown complete.")


if __name__ == "__main__":
    if API_KEY == "YOUR_GEMINI_API_KEY_HERE":
        print("="*50)
        print("ERROR: Please update the 'API_KEY' variable in the script.")
        print("="*50)
    else:
        main()